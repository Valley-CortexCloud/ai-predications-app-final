name: Weekly Predictions (Fast)

on:
  schedule:
    - cron: '30 8 * * 1'  # Monday 4:30 AM ET (8:30 UTC)
  workflow_dispatch:

jobs:
  fast-predictions:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set date
        id: date
        run: echo "DATE=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate snapshot freshness
        run: |
          python scripts/validate_snapshot.py \
            --snapshots-root data/snapshots \
            --max-age-days 7

      - name: Production inference (using cached snapshot)
        run: |
          python scripts/production_inference.py \
            --snapshots-root data/snapshots \
            --output-dir datasets \
            --model-dir model

      - name: Create Top 20 portfolio
        run: |
          python -c "
          import pandas as pd
          from pathlib import Path
          
          # Find latest predictions
          datasets_dir = Path('datasets')
          pred_files = sorted(datasets_dir.glob('predictions_*.csv'))
          
          if not pred_files:
              print('No predictions found')
              exit(1)
          
          pred_file = pred_files[-1]
          print(f'Using predictions: {pred_file}')
          
          # Load predictions
          pred_df = pd.read_csv(pred_file)
          
          # Filter and sort
          valid = pred_df.copy()
          
          if 'adv20_dollar' in valid.columns:
              valid = valid[valid['adv20_dollar'] >= 10_000_000]
          
          if 'price' in valid.columns:
              valid = valid[(valid['price'] >= 15) & (valid['price'] <= 3000)]
          
          valid = valid.sort_values('pred', ascending=False)
          
          # Top 20
          top20 = valid.head(20)[['symbol', 'pred']].reset_index(drop=True)
          top20.index += 1
          
          # Save
          date = pred_file.stem.split('_')[1]
          top20.to_csv(f'datasets/top20_{date}.csv')
          
          print(f'\nTop 20 saved to datasets/top20_{date}.csv')
          print(top20.to_string())
          "

      - name: Upload predictions as artifact
        uses: actions/upload-artifact@v4
        with:
          name: predictions-${{ steps.date.outputs.DATE }}
          path: datasets/predictions_*.csv

      - name: Upload top 20 as artifact
        uses: actions/upload-artifact@v4
        with:
          name: top20-${{ steps.date.outputs.DATE }}
          path: datasets/top20_*.csv

      - name: Commit predictions
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add only prediction files (not data cache)
          git add datasets/predictions_*.csv
          git add datasets/top20_*.csv
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Weekly predictions: $(date +'%Y-%m-%d')"
            git push
          fi

      - name: Email Top 20
        if: always()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USER }}
          password: ${{ secrets.EMAIL_PASS }}
          subject: "ðŸš€ Weekly Top 20 Alpha - ${{ steps.date.outputs.DATE }}"
          to: jvalley19@gmail.com
          from: Grok Quant Bot <jvalley19@gmail.com>
          body: |
            Pipeline run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            Attached: top20.csv (using cached snapshot - fast inference)
          attachments: datasets/top20_*.csv

  llm-supercharge:
    needs: fast-predictions
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set date
        id: date
        run: echo "DATE=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Download top20 artifact
        uses: actions/download-artifact@v4
        with:
          name: top20-${{ steps.date.outputs.DATE }}
          path: datasets/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install LLM deps
        run: pip install openai pandas

      - name: Run LLM analysis
        env:
          XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        run: python scripts/llm_supercharge.py

      - name: Upload supercharged report
        uses: actions/upload-artifact@v4
        with:
          name: supercharged-top20-${{ steps.date.outputs.DATE }}
          path: datasets/supercharged_*.csv

      - name: Email Supercharged Report
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USER }}
          password: ${{ secrets.EMAIL_PASS }}
          subject: "ðŸ§  LLM-Enhanced Top 20 - ${{ steps.date.outputs.DATE }}"
          to: jvalley19@gmail.com
          from: Grok Quant Bot <jvalley19@gmail.com>
          body: |
            LLM supercharged analysis attached!
            
            Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          attachments: datasets/supercharged_*.csv
