name: Weekly Predictions (Fast)

on:
  schedule:
    - cron: '30 8 * * 1'  # Monday 4:30 AM ET (8:30 UTC)
  workflow_dispatch:

jobs:
  fast-predictions:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Need write to commit predictions
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set date
        id: date
        run: echo "DATE=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Free up disk space (manual - safe and effective)
        run: |
          echo "Before cleanup:"
          df -h /

          sudo rm -rf /usr/share/dotnet      # ~10-17GB
          sudo rm -rf /usr/local/lib/android # ~10-15GB
          sudo rm -rf /opt/ghc               # ~3-5GB
          sudo rm -rf /opt/hostedtoolcache/CodeQL  # ~5GB
          sudo rm -rf /usr/local/.ghcup      # Haskell extras
          sudo docker image prune -a -f      # If any Docker images (optional, ~3GB)
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*

          echo "After cleanup:"
          df -h /

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate snapshot freshness
        run: |
          python scripts/validate_snapshot.py \
            --snapshots-root data/snapshots \
            --max-age-days 7

      - name: Production inference (using cached snapshot)
        run: |
          python scripts/production_inference.py \
            --snapshots-root data/snapshots \
            --output-dir datasets \
            --model-dir model

      - name: Create Top 20 portfolio
        run: |
          python scripts/create_top20.py \
            --output-dir datasets \
            --min-liquidity 10000000 \
            --min-price 15 \
            --max-price 3000

      - name: Upload predictions as artifact
        uses: actions/upload-artifact@v4
        with:
          name: predictions-${{ steps.date.outputs.DATE }}
          path: datasets/predictions_*.csv

      - name: Upload top 20 as artifact
        uses: actions/upload-artifact@v4
        with:
          name: top20-${{ steps.date.outputs.DATE }}
          path: datasets/top20_*.csv

      - name: Commit predictions
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add only prediction files (not data cache)
          git add datasets/predictions_*.csv
          git add datasets/top20_*.csv
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Weekly predictions: $(date +'%Y-%m-%d')"
            git push
          fi

      - name: Email Top 20
        if: always()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USER }}
          password: ${{ secrets.EMAIL_PASS }}
          subject: "ðŸš€ Weekly Top 20 Alpha - ${{ steps.date.outputs.DATE }}"
          to: jvalley19@gmail.com
          from: Grok Quant Bot <jvalley19@gmail.com>
          body: |
            Pipeline run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            Attached: top20.csv (using cached snapshot - fast inference)
          attachments: datasets/top20_*.csv

  llm-supercharge:
    needs: fast-predictions
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Need write to commit supercharged CSV
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          ref: main  # Get latest main after fast-predictions committed

      - name: Set date
        id: date
        run: echo "DATE=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Download top20 artifact
        uses: actions/download-artifact@v4
        with:
          name: top20-${{ steps.date.outputs.DATE }}
          path: datasets/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install LLM deps
        run: pip install openai pandas

      - name: Run LLM analysis
        env:
          XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
        run: python scripts/llm_supercharge.py

      - name: Upload supercharged report
        uses: actions/upload-artifact@v4
        with:
          name: supercharged-top20-${{ steps.date.outputs.DATE }}
          path: datasets/supercharged_*.csv

      - name: Commit supercharged CSV
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add supercharged files
          git add datasets/supercharged_*.csv
          git add datasets/supercharged_metadata_*.json
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "LLM supercharged predictions: $(date +'%Y-%m-%d')"
            git push
          fi

      - name: Email Supercharged Report
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USER }}
          password: ${{ secrets.EMAIL_PASS }}
          subject: "ðŸ§  LLM-Enhanced Top 20 - ${{ steps.date.outputs.DATE }}"
          to: jvalley19@gmail.com
          from: Grok Quant Bot <jvalley19@gmail.com>
          body: |
            LLM supercharged analysis attached and committed to repo!
            
            Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          attachments: datasets/supercharged_*.csv
